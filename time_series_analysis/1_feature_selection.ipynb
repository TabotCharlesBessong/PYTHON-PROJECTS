{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5b47f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_wine\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed42cea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (12,9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3d8853",
   "metadata": {},
   "source": [
    "## Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87161e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_data = load_wine()\n",
    "\n",
    "wine_df = pd.DataFrame(\n",
    "  data=wine_data.data,\n",
    "  columns=wine_data.feature_names\n",
    ")\n",
    "\n",
    "wine_df['target'] = wine_data.target\n",
    "wine_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5d2e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from seaborn import swarmplot\n",
    "\n",
    "data_to_plot = pd.melt(wine_df[['alcohol','malic_acid','alcalinity_of_ash','target']],id_vars='target',var_name='features',value_name='value')\n",
    "\n",
    "swarmplot(data=data_to_plot,x='features',y='value',hue='target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1569bcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0915fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "x = [0,1,2]\n",
    "y = [59,71,48]\n",
    "\n",
    "ax.bar(x,y,width=0.2)\n",
    "ax.set_xlabel('Category')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_xticks([0,1,2])\n",
    "ax.set_xticklabels([0,1,2], fontsize=12)\n",
    "\n",
    "for index, value in enumerate(y):\n",
    "  plt.text(x=int(index), y = value+1,s=str(value),ha='center')\n",
    "  \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41727daa",
   "metadata": {},
   "source": [
    "## Train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ac836c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = wine_df.drop(['target'],axis=1)\n",
    "y = wine_df['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,shuffle=True,stratify=y,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18de6698",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape,y_train.shape)\n",
    "print(X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75b708a",
   "metadata": {},
   "source": [
    "## Baseline model: Gradient Boosting Classifier with all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60802652",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Initialize classifier\n",
    "gbc = GradientBoostingClassifier(max_depth=5, random_state=42)\n",
    "\n",
    "# Train classifier using all features\n",
    "gbc.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "preds = gbc.predict(X_test)\n",
    "\n",
    "# Evaluate the model using the F1-score\n",
    "f1_score_all = round(f1_score(y_test, preds, average='weighted'), 3)\n",
    "\n",
    "print(f1_score_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec217265",
   "metadata": {},
   "source": [
    "## Feature selection techniques\n",
    "\n",
    "### Variance threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24cc5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_v1, X_test_v1, y_tain_v1, y_test_v1 = X_train.copy(), X_test.copy(), y_train.copy(), y_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efe8e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_v1.var(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e01e5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "scaled_X_train_v1 = scaler.fit_transform(X_train_v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb7ce4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "x = X.columns\n",
    "y = scaled_X_train_v1.var(axis=0)\n",
    "\n",
    "ax.bar(x, y, width=0.2)\n",
    "ax.set_xlabel('Features')\n",
    "ax.set_ylabel('Variance')\n",
    "ax.set_ylim(0, 0.1)\n",
    "\n",
    "for index, value in enumerate(y):\n",
    "    plt.text(x=index, y=value+0.001, s=str(round(value, 3)), ha='center')\n",
    "    \n",
    "fig.autofmt_xdate()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666aa99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_X_train_v1 = X_train_v1.drop(['ash', 'magnesium'], axis=1)\n",
    "sel_X_test_v1 = X_test_v1.drop(['ash', 'magnesium'], axis=1)\n",
    "\n",
    "gbc.fit(sel_X_train_v1, y_train)\n",
    "\n",
    "var_preds = gbc.predict(sel_X_test_v1)\n",
    "\n",
    "f1_score_var = round(f1_score(y_test_v1, var_preds, average='weighted'), 3)\n",
    "\n",
    "print(f1_score_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bde4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "x = ['All features', 'Variance threshold']\n",
    "y = [f1_score_all, f1_score_var]\n",
    "\n",
    "ax.bar(x, y, width=0.2)\n",
    "ax.set_xlabel('Feature selection method')\n",
    "ax.set_ylabel('F1-Score (weighted)')\n",
    "ax.set_ylim(0, 1.2)\n",
    "\n",
    "for index, value in enumerate(y):\n",
    "    plt.text(x=index, y=value+0.01, s=str(round(value,3)), ha='center')\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5531c6ca",
   "metadata": {},
   "source": [
    "## K-best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6494f55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_v2, X_test_v2, y_train_v2, y_test_v2 = X_train.copy(), X_test.copy(), y_train.copy(), y_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d51a9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "f1_score_list = []\n",
    "\n",
    "for k in range(1, 14):\n",
    "    selector = SelectKBest(mutual_info_classif, k=k)\n",
    "    selector.fit(X_train_v2, y_train_v2)\n",
    "    \n",
    "    sel_X_train_v2 = selector.transform(X_train_v2)\n",
    "    sel_X_test_v2 = selector.transform(X_test_v2)\n",
    "    \n",
    "    gbc.fit(sel_X_train_v2, y_train_v2)\n",
    "    kbest_preds = gbc.predict(sel_X_test_v2)\n",
    "    \n",
    "    f1_score_kbest = round(f1_score(y_test_v2, kbest_preds, average='weighted'), 3)\n",
    "    \n",
    "    f1_score_list.append(f1_score_kbest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705503d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "x = np.arange(1, 14)\n",
    "y = f1_score_list\n",
    "\n",
    "ax.bar(x, y, width=0.2)\n",
    "ax.set_xlabel('Number of features selected using mutual information')\n",
    "ax.set_ylabel('F1-Score (weighted)')\n",
    "ax.set_ylim(0, 1.2)\n",
    "ax.set_xticks(np.arange(1, 14))\n",
    "ax.set_xticklabels(np.arange(1, 14), fontsize=12)\n",
    "\n",
    "for i, v in enumerate(y):\n",
    "    plt.text(x=i+1, y=v+0.05, s=str(v), ha='center')\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f197d38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = SelectKBest(mutual_info_classif, k=3)\n",
    "selector.fit(X_train_v2, y_train_v2)\n",
    "\n",
    "selected_feature_mask = selector.get_support()\n",
    "\n",
    "selected_features = X_train_v2.columns[selected_feature_mask]\n",
    "\n",
    "selected_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8a6e24",
   "metadata": {},
   "source": [
    "## Recursive feature elimination (RFE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df3fba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_v3, X_test_v3, y_train_v3, y_test_v3 = X_train.copy(), X_test.copy(), y_train.copy(), y_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e66a329",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "rfe_f1_score_list = []\n",
    "\n",
    "for k in range(1, 14):\n",
    "    RFE_selector = RFE(estimator=gbc, n_features_to_select=k, step=1)\n",
    "    RFE_selector.fit(X_train_v3, y_train_v3)\n",
    "    \n",
    "    sel_X_train_v3 = RFE_selector.transform(X_train_v3)\n",
    "    sel_X_test_v3 = RFE_selector.transform(X_test_v3)\n",
    "    \n",
    "    gbc.fit(sel_X_train_v3, y_train_v3)\n",
    "    RFE_preds = gbc.predict(sel_X_test_v3)\n",
    "    \n",
    "    f1_score_rfe = round(f1_score(y_test_v3, RFE_preds, average='weighted'), 3)\n",
    "    \n",
    "    rfe_f1_score_list.append(f1_score_rfe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82699127",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "x = np.arange(1, 14)\n",
    "y = rfe_f1_score_list\n",
    "\n",
    "ax.bar(x, y, width=0.2)\n",
    "ax.set_xlabel('Number of features selected using RFE')\n",
    "ax.set_ylabel('F1-Score (weighted)')\n",
    "ax.set_ylim(0, 1.2)\n",
    "ax.set_xticks(np.arange(1, 14))\n",
    "ax.set_xticklabels(np.arange(1, 14), fontsize=12)\n",
    "\n",
    "for i, v in enumerate(y):\n",
    "    plt.text(x=i+1, y=v+0.05, s=str(v), ha='center')\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d077de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "RFE_selector = RFE(estimator=gbc, n_features_to_select=3, step=10)\n",
    "RFE_selector.fit(X_train_v3, y_train_v3)\n",
    "\n",
    "selected_features_mask = RFE_selector.get_support()\n",
    "\n",
    "selected_features = X_train_v3.columns[selected_features_mask]\n",
    "selected_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c126b831",
   "metadata": {},
   "source": [
    "## Boruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a61acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_v4, X_test_v4, y_train_v4, y_test_v4 = X_train.copy(), X_test.copy(), y_train.copy(), y_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bb0e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from boruta import BorutaPy\n",
    "\n",
    "boruta_selector = BorutaPy(gbc, random_state=42)\n",
    "\n",
    "boruta_selector.fit(X_train_v4.values, y_train_v4.values.ravel())\n",
    "\n",
    "sel_X_train_v4 = boruta_selector.transform(X_train_v4.values)\n",
    "sel_X_test_v4 = boruta_selector.transform(X_test_v4.values)\n",
    "\n",
    "gbc.fit(sel_X_train_v4, y_train_v4)\n",
    "\n",
    "boruta_preds = gbc.predict(sel_X_test_v4)\n",
    "\n",
    "boruta_f1_score = round(f1_score(y_test_v4, boruta_preds, average='weighted'), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11af6404",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features_mask = boruta_selector.support_\n",
    "\n",
    "selected_features = X_train_v4.columns[selected_features_mask]\n",
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d170b745",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "x = ['All features (13)', 'Variance threshold (11)', 'Filter - MI (3)', 'RFE (3)', 'Boruta (9)']\n",
    "y = [f1_score_all, f1_score_var, 0.981, 1.0, boruta_f1_score]\n",
    "\n",
    "ax.bar(x, y, width=0.2)\n",
    "ax.set_xlabel('Feature selection method')\n",
    "ax.set_ylabel('F1-Score (weighted)')\n",
    "ax.set_ylim(0, 1.2)\n",
    "\n",
    "for i, v in enumerate(y):\n",
    "    plt.text(x=i, y=v+0.01, s=str(v), ha='center')\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a004a042",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
